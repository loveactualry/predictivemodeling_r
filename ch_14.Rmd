---
title: "ch14"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.



```{r}
a = c(91, 20, 30, 67)
ex_14_a = matrix(a, nrow = 2, ncol = 2)
# test_14 = as_tibble(ex_14_a)
x1 <- data.frame(ex_14_a)
x1["colsum",] <- apply(x1, 2, sum)
x1$rowsum <- apply(x1, 1, sum)
x1
```

- 하나의 분기점에 여러 지니 계수를 구하는 버
```{r}
Sys.setlocale('LC_ALL','C')
# calculate
# before split ginie value
a = 2*((x1[1,1]/x1[1,3])*(x1[1,2]/x1[1,3]))

b = 2*((x1[2,1]/x1[2,3])*(x1[2,2]/x1[2,3]))

# 분기 후 지니계수 1,2
c = x1[1,3]/x1[3,3]

d = x1[2,3]/x1[3,3]

# 분기 후 총 지니 계수
e = a*c + b*d
e
```

> 이론

- 현재는 하나의 지니계수만 구했지만 분할 알고리즘에서 모든 분기점에 대해 구하고 순도수치 최소화 분기 값 계산
    - 반복 되므로 중단 기준 필요

- 최대 깊이가 주어지는 트리 -> 훈련 데이터 과적합 우려
- 복잡도 인수 -> 순도 기준이 마지막 노드 값에 벌점이 매겨지는 방식이다.(8.1 참조) 8장가서 봐야지..

- 훈련된 트리를 예측에 사용.
- 만약예측 변수가 B=0.1로 한다면 클래스 1,2의 예측값은 0.23, 0.77 이다.
    - 해당 알고리즘 기준으로 thread 값 변화에 따라 예측값이 변한다는 의미를 얘기 해주고 싶은건지..?
  
* 결측값이 있다면 분류 트리는 어떻게 분리 할까?
    + 회귀 트리와 비슷한 방식으로 처리
    + 결측 정보가 없는 샘플만 처리 (8.1 참조)
    + 예측 -> 결측값이 있으면 다른 분기점 사용

* 변수가 연속형이라면?
    + 분할 프로세스는 명확히 보인다.
    
* 변수가 범주형이라면?
    + 일반적 통계 모형과는 다른 방법. 이항 가변수(1,0)을 만들어 구분하고 모델에 포함시킨다.
    + 새 예측 변수가 하나의 분기점을 갖게 되어 순도를 쉽게 구할 수 있다.
    + 1에 대해 0,1 로 구분하여 하나의 분기점을 만든다는 의미
    
* 범주형 데이터를 어떻게 처리할지 결정해야 한다. 
    + 그룹 범주 방식 - 범주형 변수를 모델에 그냥 넣는 방법. 어떻게 묶을지 설정에서 결정
    + 개별 범주 방식 - 범주형 변수에 이항 가변수를 넣고 그것에 따라 나누는 것.
    + 모델을 돌려보면서 선택해야 한다. 만약 모델 예측력이 높다면 그룹 범주 방식을 사용하는게 좋다.
        + 예전에 범주형 의사결정 나무를 그리면서 개별 범주 방식으로 그렸던 기억이 있다.
    
* 범주형 변수의 분할 과정
    + 첫번째 분기는 17개 범주를 갖는 계약값 그룹
    + 14.3을 보았을 때, I,J,P,unkonw 그룹 그 이외의 변수로 나누었다. 
    + 최적 분할을 결정 전에 범주를 결정하는 것이 합리적이다.
        + 하지만 의사결정 나무는 greedy(탐욕 알고리즘)방식을 사용한다.
    + greedy(탐욕알고리즘) -> 의사 결정 나무를 분리할 때 눈앞에 있는 범주들의 분리 값을 최우선으로 한다. 
        + 마지막에 최선으로 나눠지는 것을 고려하지 않고 나눠보면서 최적의 알고리즘을 찾는다는 의미
        + 그 순간 최선의 답을 찾아나간다고 이해하면 될듯
        
    + 범주의 비율에 따라 정렬하는 방법
        + 14.2의 상위 그래프는 보조금 지원 성공 확률 의미. 지니계수는 정렬된 범주를 분할 하고 있음.
        + 14.2의 하위 그래프의 지니계수를 살펴보면 3개 범주 추가하는 경우 지니계수가 낮아지는 것을 확인.
        + I,M 범주 분기에서 지니 계수가 가장 낮게 나올 것으로 파악하고 이 지점에서 분기 되었을 것으로 파악.
        + I, J, P, Un 으로 구분하고 나머지 그룹으로 분리 하고 실패와 성공으로 분리 하게 된다.
        


![그림 14.2](https://github.com/topepo/APM_Figures/blob/master/Chapter_14_Classification_Trees_and_Rule-Based_Models/Ch14Fig02.png?raw=true)



![그림 14.3](https://github.com/topepo/APM_Figures/blob/master/Chapter_14_Classification_Trees_and_Rule-Based_Models/Ch14Fig03.png?raw=true)


    
![그림 14.4](https://github.com/topepo/APM_Figures/blob/master/Chapter_14_Classification_Trees_and_Rule-Based_Models/Ch14Fig04.png?raw=true)


  + 14.3과 14.4 그림의 차이
      + 14.3 : 예측 변수를 그룹 범주로 둔 경우. 14.4 CART(classification and regression tree)를 각각 범주형 변수를 사용해 만든 경우
      + 상세 설명 
      + 14.3 예측 변수(0,1)이 명확하지 않고 병합되어 있다. 위의 설명 처럼 i,j,p,un 그룹을 실패로 나머지를 성공으로 하여 트리 해석이 어려움.
      + 그러나 예측 변수와 응답 변수 간의 관계를 가지고 파악은 가능
      + 14.4 개별 범주로 나눈 경우(0,1) 최종적으로는 16개 노드를 갖는다. 생각보다 많이 가지치기가 되지는 않았다.16개에 비해..
      
![그림 14.5](https://github.com/topepo/APM_Figures/blob/master/Chapter_14_Classification_Trees_and_Rule-Based_Models/Ch14Fig05.png?raw=true)
    
    
* 14.5 그림상으로 보았을 때 큰 차이는 없어 보인다... 그룹 범주, 개별 범주 다 0.98이다.



* 
    
    
```{r}

```








